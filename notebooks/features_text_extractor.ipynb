{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orietta's Recipes</td>\n",
       "      <td>2020-01-23 18:13:47</td>\n",
       "      <td>La mia cena! Mozzarella in carrozza üç∑üç∑‚ò∫Ô∏è. Voi ...</td>\n",
       "      <td>19</td>\n",
       "      <td>95</td>\n",
       "      <td>0.014381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orietta's Recipes</td>\n",
       "      <td>2020-01-23 11:42:55</td>\n",
       "      <td>Buon pranzo a tutti! üòã Oggi spatzle con filett...</td>\n",
       "      <td>14</td>\n",
       "      <td>79</td>\n",
       "      <td>0.011959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Orietta's Recipes</td>\n",
       "      <td>2020-01-23 07:55:06</td>\n",
       "      <td>Eccomi con la miaüòç NUOVA üòç ricetta, per colazi...</td>\n",
       "      <td>25</td>\n",
       "      <td>98</td>\n",
       "      <td>0.014835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Orietta's Recipes</td>\n",
       "      <td>2020-01-22 17:59:47</td>\n",
       "      <td>√à quasi ora di cena! Io ho un po' di fame  ‚ò∫Ô∏è‚ò∫...</td>\n",
       "      <td>24</td>\n",
       "      <td>106</td>\n",
       "      <td>0.016046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orietta's Recipes</td>\n",
       "      <td>2020-01-22 11:30:14</td>\n",
       "      <td>Arriva l'ora di pranzo e viene voglia di un pi...</td>\n",
       "      <td>26</td>\n",
       "      <td>108</td>\n",
       "      <td>0.016349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         screen_name                 date  \\\n",
       "0  Orietta's Recipes  2020-01-23 18:13:47   \n",
       "1  Orietta's Recipes  2020-01-23 11:42:55   \n",
       "2  Orietta's Recipes  2020-01-23 07:55:06   \n",
       "3  Orietta's Recipes  2020-01-22 17:59:47   \n",
       "4  Orietta's Recipes  2020-01-22 11:30:14   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  La mia cena! Mozzarella in carrozza üç∑üç∑‚ò∫Ô∏è. Voi ...             19   \n",
       "1  Buon pranzo a tutti! üòã Oggi spatzle con filett...             14   \n",
       "2  Eccomi con la miaüòç NUOVA üòç ricetta, per colazi...             25   \n",
       "3  √à quasi ora di cena! Io ho un po' di fame  ‚ò∫Ô∏è‚ò∫...             24   \n",
       "4  Arriva l'ora di pranzo e viene voglia di un pi...             26   \n",
       "\n",
       "   favourites_count     ratio  \n",
       "0                95  0.014381  \n",
       "1                79  0.011959  \n",
       "2                98  0.014835  \n",
       "3               106  0.016046  \n",
       "4               108  0.016349  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/raw_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chars, question_marks, esclamation_marks, emojis, hashtags, tags, urls, consecutive_chars, plain_text  = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    tweet = row.text\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    nr_question_marks, nr_esclamation_marks = 0, 0\n",
    "\n",
    "    # question and esclamation marks\n",
    "    for token in tokens:\n",
    "        if token == '?':\n",
    "            nr_question_marks += 1\n",
    "        if token == '!':\n",
    "            nr_esclamation_marks += 1\n",
    "\n",
    "    # emoji\n",
    "    allchars = [str for str in tweet]\n",
    "    lista = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    nr_emoji = len(lista)\n",
    "    for c in tweet:\n",
    "        if c in lista:\n",
    "            tweet = tweet.replace(c, \"\")\n",
    "\n",
    "    # hashtags\n",
    "    try:\n",
    "        nr_hashtags = len(re.findall(r\"#(\\w+)\", tweet))\n",
    "        tweet = re.sub(r\"#(\\w+)\", \"\", tweet, count=nr_hashtags)\n",
    "    except Exception:\n",
    "        nr_hashtags = 0\n",
    "\n",
    "\n",
    "    # tags\n",
    "    try:\n",
    "        nr_tags = len(re.findall(r\" @(\\w+)\", tweet))\n",
    "        tweet = re.sub(r\" @(\\w+)\", \"\", tweet, count=nr_tags)\n",
    "    except Exception:\n",
    "        nr_tags = 0\n",
    "\n",
    "    # urls\n",
    "    try:\n",
    "        nr_urls = len(re.findall(r\"http[s]?://([a-zA-Z0-9/.]+)\", tweet))\n",
    "        tweet = re.sub(r\"http[s]?://([a-zA-Z0-9/.]+)\", \"\", tweet, count=nr_urls)\n",
    "    except Exception:\n",
    "        nr_urls = 0\n",
    "\n",
    "    # consecutive chars\n",
    "    try:\n",
    "        nr_consecutive_chars = len(re.findall(r\"(A-Za-z){3,}\", tweet))\n",
    "        tweet = re.sub(r\"http[s]?://([a-zA-Z0-9/.]+)\", \"\", tweet, count=nr_urls)\n",
    "    except Exception:\n",
    "        nr_consecutive_chars = 0\n",
    "        \n",
    "    # special characters\n",
    "    tweet = re.sub('[^A-Za-z0-9 ]+', '', tweet)\n",
    "    plain_text.append(tweet)    \n",
    "    \n",
    "    # no spaces\n",
    "    try:\n",
    "        tweet = re.sub(\" \", \"\", tweet, len(re.findall(\" \", tweet)))\n",
    "    except Exception:\n",
    "        \"Error: spaces have not be deleted from the tweet.\"\n",
    "    \n",
    "    chars.append(len(tweet))\n",
    "    question_marks.append(nr_question_marks)\n",
    "    esclamation_marks.append(nr_esclamation_marks)\n",
    "    emojis.append(nr_emoji)\n",
    "    hashtags.append(nr_hashtags)\n",
    "    tags.append(nr_tags)\n",
    "    urls.append(nr_urls)\n",
    "    consecutive_chars.append(nr_consecutive_chars)\n",
    "\n",
    "df['len_plain_text'] = chars\n",
    "df['question_marks'] = question_marks\n",
    "df['esclamation_marks'] = esclamation_marks\n",
    "df['emojis'] = emojis\n",
    "df['hashtags'] = hashtags\n",
    "df['tags'] = tags\n",
    "df['urls'] = urls\n",
    "df['consecutive_chars'] = consecutive_chars\n",
    "df['plain_text'] = plain_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF SUM FOR EACH TWEET \n",
    "- #### CORPUS = set of tweets of the current page\n",
    "- #### tf-idf calulated on plain text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the corpus for each page of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df.screen_name.unique()\n",
    "\n",
    "corpus_list = []\n",
    "\n",
    "for name in names:\n",
    "    temp = df[df.screen_name == name]\n",
    "    corpus = []\n",
    "    for index, row in temp.iterrows():\n",
    "        corpus.append(row.plain_text)\n",
    "    corpus_list.append(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram (1,2) tokenization and tf-idf calculation for each word in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(use_idf=True, ngram_range=(1, 2))\n",
    "\n",
    "tf_idf_sum = []\n",
    "\n",
    "for corpus in corpus_list:\n",
    "    tfidf_vectors_list = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    for element in tfidf_vectors_list:\n",
    "        tf_idf_tweet = round(float(sum(element.T.todense())), 8)\n",
    "        tf_idf_sum.append(tf_idf_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_idf_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tf-idf_sum'] = tf_idf_sum\n",
    "df = df.drop(columns=\"plain_text\")\n",
    "df.to_csv(\"../dataset/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
