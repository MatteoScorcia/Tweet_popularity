{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.tag import pos_tag, map_tag\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CookGlobal</td>\n",
       "      <td>2020-01-23 21:15:09</td>\n",
       "      <td>Creamy #vegan dressings are delicious, lower i...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CookGlobal</td>\n",
       "      <td>2020-01-23 19:15:07</td>\n",
       "      <td>It‚Äôs almost the weekend!  So, it‚Äôs the perfect...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CookGlobal</td>\n",
       "      <td>2020-01-23 17:15:02</td>\n",
       "      <td>My first experiment with homemade #vegan ‚Äúchee...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CookGlobal</td>\n",
       "      <td>2020-01-23 15:15:04</td>\n",
       "      <td>The weekend is almost here! üôåüèº.  So, it‚Äôs the ...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CookGlobal</td>\n",
       "      <td>2020-01-23 14:15:10</td>\n",
       "      <td>Easy Peanut Butter Cookies make such a tasty t...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.002566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  screen_name                 date  \\\n",
       "0  CookGlobal  2020-01-23 21:15:09   \n",
       "1  CookGlobal  2020-01-23 19:15:07   \n",
       "2  CookGlobal  2020-01-23 17:15:02   \n",
       "3  CookGlobal  2020-01-23 15:15:04   \n",
       "4  CookGlobal  2020-01-23 14:15:10   \n",
       "\n",
       "                                                text  retweet_count     ratio  \n",
       "0  Creamy #vegan dressings are delicious, lower i...              6  0.001649  \n",
       "1  It‚Äôs almost the weekend!  So, it‚Äôs the perfect...              8  0.002199  \n",
       "2  My first experiment with homemade #vegan ‚Äúchee...              0  0.000000  \n",
       "3  The weekend is almost here! üôåüèº.  So, it‚Äôs the ...             16  0.002932  \n",
       "4  Easy Peanut Butter Cookies make such a tasty t...              7  0.002566  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/raw_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars, question_marks, esclamation_marks, emojis, hashtags, tags, urls, pos_count  = [], [], [], [], [], [], [], []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    tweet = row.text\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    nr_question_marks, nr_esclamation_marks = 0, 0\n",
    "\n",
    "    # question and esclamation marks\n",
    "    for token in tokens:\n",
    "        if token == '?':\n",
    "            nr_question_marks += 1\n",
    "        if token == '!':\n",
    "            nr_esclamation_marks += 1\n",
    "\n",
    "    # emoji\n",
    "    allchars = [str for str in tweet]\n",
    "    lista = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    nr_emoji = len(lista)\n",
    "    for c in tweet:\n",
    "        if c in lista:\n",
    "            tweet = tweet.replace(c, \"\")\n",
    "\n",
    "    # hashtags\n",
    "    try:\n",
    "        nr_hashtags = len(re.findall(r\"#(\\w+)\", tweet))\n",
    "        tweet = re.sub(r\"#(\\w+)\", \"\", tweet, count=nr_hashtags)\n",
    "    except Exception:\n",
    "        nr_hashtags = 0\n",
    "\n",
    "\n",
    "    # tags\n",
    "    try:\n",
    "        nr_tags = len(re.findall(r\" @(\\w+)\", tweet))\n",
    "        tweet = re.sub(r\" @(\\w+)\", \"\", tweet, count=nr_tags)\n",
    "    except Exception:\n",
    "        nr_tags = 0\n",
    "\n",
    "    # urls\n",
    "    try:\n",
    "        nr_urls = len(re.findall(r\"http[s]?://([a-zA-Z0-9/.]+)\", tweet))\n",
    "        tweet = re.sub(r\"http[s]?://([a-zA-Z0-9/.]+)\", \"\", tweet, count=nr_urls)\n",
    "    except Exception:\n",
    "        nr_urls = 0\n",
    "        \n",
    "    # special characters\n",
    "    tweet = re.sub('[^A-Za-z0-9 ]+', '', tweet)\n",
    "    \n",
    "    #POS TAGGING\n",
    "    _UNIVERSAL_TAGS = (\n",
    "    \"VERB\",\n",
    "    \"NOUN\",\n",
    "    \"ADJ\",\n",
    "    \"ADV\",\n",
    "    )\n",
    "    \n",
    "    pos = nltk.pos_tag(tweet.split())\n",
    "    simplifiedPos = [(word, map_tag('en-ptb', 'universal', tag)) for word, tag in pos]\n",
    "    \n",
    "    universal_tags_list = list(_UNIVERSAL_TAGS)\n",
    "    count = []\n",
    "    for i in range(0, len(universal_tags_list)):\n",
    "        count.append(0)\n",
    "    \n",
    "    for element in simplifiedPos:\n",
    "        for index, target in enumerate(universal_tags_list):\n",
    "            if target==element[1]:\n",
    "                count[index] += 1\n",
    "    pos_count.append(count)\n",
    "    \n",
    "    # no spaces\n",
    "    try:\n",
    "        tweet = re.sub(\" \", \"\", tweet, len(re.findall(\" \", tweet)))\n",
    "    except Exception:\n",
    "        \"Error: spaces have not be deleted from the tweet.\"\n",
    "    \n",
    "    chars.append(len(tweet))\n",
    "    question_marks.append(nr_question_marks)\n",
    "    esclamation_marks.append(nr_esclamation_marks)\n",
    "    emojis.append(nr_emoji)\n",
    "    hashtags.append(nr_hashtags)\n",
    "    tags.append(nr_tags)\n",
    "    urls.append(nr_urls)\n",
    "\n",
    "df['plain_text_len'] = chars\n",
    "df['question_marks'] = question_marks\n",
    "df['esclamation_marks'] = esclamation_marks\n",
    "df['emojis'] = emojis\n",
    "df['hashtags'] = hashtags\n",
    "df['tags'] = tags\n",
    "df['urls'] = urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(pos_count, columns=universal_tags_list)\n",
    "df.drop(columns=[\"ratio\", \"date\", \"text\"], inplace=True)\n",
    "\n",
    "result = pd.concat([df, df1], axis=1, sort=False)\n",
    "\n",
    "#rename columns\n",
    "\n",
    "result.rename(columns = {'VERB': 'verbs', 'NOUN': 'nouns', 'ADJ' : 'adjs', 'ADV' : 'advs'}, inplace = True)\n",
    "\n",
    "#save results\n",
    "result.to_csv(\"../dataset/dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
